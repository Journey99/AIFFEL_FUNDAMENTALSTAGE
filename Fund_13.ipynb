{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2496714d",
   "metadata": {},
   "source": [
    "# 18. 딥러닝 들여다보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7144bc",
   "metadata": {},
   "source": [
    "## 학습목표\n",
    "- 딥러닝 문제 구성에 대한 기본적인 이해를 높인다.\n",
    "- Neural Network에 사용되는 용어들에 대한 이해를 높인다.\n",
    "- 딥러닝 프레임워크를 사용하지 않고, Numpy만을 이용해 딥러닝 모델과 훈련 과정을 직접 구현해 본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d25c444",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcd55b0",
   "metadata": {},
   "source": [
    "## 18.2 신경망 구성 (1) 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba1636f",
   "metadata": {},
   "source": [
    "### 신경망이란?\n",
    "- 뇌에는 1000억 개에 가까운 신경계 뉴런들이 있다고 한다. 이 뉴런들은 서로 매우 복잡하게 얽혀 있고, 조금 물러서서 보면 하나의 거대한 그물망과 같은 형태를 이루고 있습니다. 보통 우리는 이를 신경망이라고 부른다\n",
    "\n",
    "### 퍼셉트론\n",
    "- 머신러닝/딥러닝 과학자들도 자연에서 답을 찾으려 노력했고, 우리 뇌 속의 신경망 구조에 착안해서 퍼셉트론(Perceptron)이라는 형태를 제안하며 이를 연결한 형태를 인공신경망(Artificial Neural Network)이라고 부르기 시작했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314a7617",
   "metadata": {},
   "source": [
    "### MNIST Revisited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8e23a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 39,760\n",
      "Trainable params: 39,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 1ms/step - loss: 0.4978 - accuracy: 0.8799\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2329 - accuracy: 0.9340\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1830 - accuracy: 0.9482\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1527 - accuracy: 0.9561\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1317 - accuracy: 0.9620\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1153 - accuracy: 0.9671\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1033 - accuracy: 0.9704\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0927 - accuracy: 0.9734\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0841 - accuracy: 0.9758\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0771 - accuracy: 0.9778\n",
      "313/313 - 0s - loss: 0.1080 - accuracy: 0.9683\n",
      "test_loss: 0.10804132372140884 \n",
      "test_accuracy: 0.9682999849319458\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MNIST 데이터를 로드. 다운로드하지 않았다면 다운로드까지 자동으로 진행됩니다. \n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()   \n",
    "\n",
    "# 모델에 맞게 데이터 가공\n",
    "x_train_norm, x_test_norm = x_train / 255.0, x_test / 255.0\n",
    "x_train_reshaped = x_train_norm.reshape(-1, x_train_norm.shape[1]*x_train_norm.shape[2])\n",
    "x_test_reshaped = x_test_norm.reshape(-1, x_test_norm.shape[1]*x_test_norm.shape[2])\n",
    "\n",
    "# 딥러닝 모델 구성 - 2 Layer Perceptron\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(50, activation='sigmoid', input_shape=(784,)))  # 입력층 d=784, 은닉층 레이어 H=50\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))   # 출력층 레이어 K=10\n",
    "model.summary()\n",
    "\n",
    "# 모델 구성과 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train_reshaped, y_train, epochs=10)\n",
    "\n",
    "# 모델 테스트 결과\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c5d9f1",
   "metadata": {},
   "source": [
    "### 다층 퍼셉트론 Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1064b0",
   "metadata": {},
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/f-14-1.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14b18fc",
   "metadata": {},
   "source": [
    "- 위에서 보았던 예시 코드와도 동일하다. 은닉층에는 H개의 노드가, 출력층에서 K개의 노드가 존재하는 인공신경망을 표현(+1 부분은 bias를 뜻하는 부분이므로 이전 레이어와의 연결이 없다) 위의 코드에서는 H=50, K=10, 그리고 입력층 노드 개수 d=784로 정의되었다.\n",
    "- 인공신경망 중에서도 위의 이미지처럼 2개 이상의 레이어를 쌓아서 만든 것을 보통 다층 퍼세트론(Multi-Layer Perceptron; MLP)라고 부른다.\n",
    "    - 입력층,출력층을 제외한 은닉층이 많아지면 많아질수록 인경신경망이 DEEP 해졌다고 이야기 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d45625",
   "metadata": {},
   "source": [
    "### Parameters/Weights\n",
    "- 앞에서 설명한 입력층-은닉층, 은닉층-출력층 사이에는 사실 각각 행렬(Matrix)이 존재\n",
    "    - 예를 들어 입력값이 100개, 은닉 노드가 20개라면 사실 이 입력층-은닉층 사이에는 100x20의 형태를 가진 행렬이 존재\n",
    "- 이 행렬들을 Parameter 혹은 Weigth라고 부른다\n",
    "- 이때 인접한 레이어 사이에는 아래와 같은 관계가 성립한다\n",
    "    - y = W * X + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "012c23e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(5, 784)\n"
     ]
    }
   ],
   "source": [
    "# 입력층 데이터의 모양(shape)\n",
    "print(x_train_reshaped.shape)\n",
    "\n",
    "# 테스트를 위해 x_train_reshaped의 앞 5개의 데이터를 가져온다.\n",
    "X = x_train_reshaped[:5]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e234bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50)\n",
      "(50,)\n",
      "(5, 50)\n"
     ]
    }
   ],
   "source": [
    "weight_init_std = 0.1\n",
    "input_size = 784\n",
    "hidden_size=50\n",
    "\n",
    "# 인접 레이어간 관계를 나타내는 파라미터 W를 생성하고 random 초기화\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)  \n",
    "# 바이어스 파라미터 b를 생성하고 Zero로 초기화\n",
    "b1 = np.zeros(hidden_size)\n",
    "\n",
    "a1 = np.dot(X, W1) + b1   # 은닉층 출력\n",
    "\n",
    "print(W1.shape)\n",
    "print(b1.shape)\n",
    "print(a1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4703473f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.48000378, -0.09311478,  0.98811026,  0.28106742,  0.75605017,\n",
       "        0.71872537,  0.90274966,  0.61319868, -0.76452785,  0.11451008,\n",
       "        0.32919812, -0.80672037, -1.431821  , -0.26603982,  0.06855826,\n",
       "        0.77026696, -0.97827646,  0.62833935,  0.60525788, -0.33447729,\n",
       "        0.20102961,  1.15812979,  0.15159911,  0.81616607, -0.36752266,\n",
       "        0.78886739,  0.93627876, -1.03315555, -0.58989192, -0.64487047,\n",
       "        0.33764913, -0.51903597,  2.19972966,  0.96206224,  0.76221968,\n",
       "       -0.3834458 ,  0.5393047 , -0.42886908,  0.26770964,  0.22690898,\n",
       "       -1.00112489, -0.29879002, -1.97091128,  1.3341708 , -1.10619453,\n",
       "        0.73210267,  0.52767533,  1.01881908, -0.23761127,  0.60343634])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번째 데이터의 은닉층 출력을 확인해 봅시다.  50dim의 벡터가 나오나요?\n",
    "a1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b456a66f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60119d83",
   "metadata": {},
   "source": [
    "## 18.3 신경망 구성 (2) 활성화 함수와 손실 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6ee6d6",
   "metadata": {},
   "source": [
    "### 활성화 함수(Activation Functions)\n",
    "- 딥러닝에서는 이 활성화 함수의 존재가 필수적이다. 활성화 함수는 보통 비선형 함수를 사용하는데 이 비선형 함수를 MLP 안에 포함시키면서 모델의 표현력이 좋아지게 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c04974",
   "metadata": {},
   "source": [
    "#### 1. Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef7ef8d",
   "metadata": {},
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/f-14-2.max-800x600.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "112d5706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38225123 0.47673811 0.7287145  0.5698079  0.68049557 0.67232627\n",
      " 0.71151423 0.64867012 0.31766403 0.52859628 0.58156425 0.30858981\n",
      " 0.19281511 0.43387957 0.51713285 0.68357864 0.27323391 0.65211282\n",
      " 0.6468583  0.41715163 0.55008883 0.76099272 0.53782736 0.6934219\n",
      " 0.40913977 0.68758809 0.71834737 0.26247279 0.35665965 0.34414639\n",
      " 0.58361935 0.37307768 0.90022523 0.72353451 0.68183546 0.40529608\n",
      " 0.63165066 0.39439642 0.56653054 0.5564851  0.26872031 0.4258533\n",
      " 0.12229104 0.7915297  0.24858103 0.67526652 0.62894076 0.73474251\n",
      " 0.4408751  0.64644209]\n"
     ]
    }
   ],
   "source": [
    "# 위 수식의 sigmoid 함수를 구현해 봅니다.\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))  \n",
    "\n",
    "\n",
    "z1 = sigmoid(a1)\n",
    "print(z1[0])  # sigmoid의 출력은 모든 element가 0에서 1사이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea5813b",
   "metadata": {},
   "source": [
    "- 현재는 ReLU 함수를 더 많이 사용한다\n",
    "    - vanishing gradient 현상이 발생한다\n",
    "    - exp 함수 사용 시 비용이 크다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808d574c",
   "metadata": {},
   "source": [
    "#### 2. Tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39cbd43",
   "metadata": {},
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/f-14-3.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6510e8b5",
   "metadata": {},
   "source": [
    "- tanh 함수는 함수의 중심값을 0으로 옮겨 sigmoid의 최적화 과정이 느려지는 문제를 해결\n",
    "- vanishing gradient 문제 존재"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e43c761",
   "metadata": {},
   "source": [
    "#### 3. ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1596c2b1",
   "metadata": {},
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/f-14-4.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058f4677",
   "metadata": {},
   "source": [
    "- sigmoid,tanh 함수에 비해 학습이 빠름\n",
    "- 연산 비용이 크지 않고, 구현이 매우 간단하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e2ebd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go~\n"
     ]
    }
   ],
   "source": [
    "# 단일 레이어 구현 함수\n",
    "def affine_layer_forward(X, W, b):\n",
    "    y = np.dot(X, W) + b\n",
    "    cache = (X, W, b)\n",
    "    return y, cache\n",
    "\n",
    "print('go~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b986a498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.323908    0.69968954  0.30211882 -0.1083326   0.48296207  0.18395559\n",
      " -0.57147778  0.15998891  0.32103281 -0.50906487]\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_size = 50\n",
    "output_size = 10\n",
    "\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "z1 = sigmoid(a1)\n",
    "a2, cache2 = affine_layer_forward(z1, W2, b2)    # z1이 다시 두번째 레이어의 입력이 됩니다. \n",
    "\n",
    "print(a2[0])  # 최종 출력이 output_size만큼의 벡터가 되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbc4f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a2에 softmax 함수 적용\n",
    "\n",
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "\n",
    "    x = x - np.max(x) # 오버플로 대책\n",
    "    return np.exp(x) / np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95a08dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06274912, 0.17464268, 0.11735122, 0.07784502, 0.14061344,\n",
       "       0.10427255, 0.04898797, 0.10180319, 0.11959193, 0.05214288])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = softmax(a2)\n",
    "y_hat[0]  # 10개의 숫자 중 하나일 확률이 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24265dc",
   "metadata": {},
   "source": [
    "### 손실함수 (Loss Functions)\n",
    "- 이렇게 비선형 활성화 함수를 가진 여러 개의 은닉층을 거친 다음 신호 정보들은 출력층으로 전달된다. 이때 우리가 원하는 정답과 전달된 신호 정보들 사이의 차이를 계산하고, 이 차이를 줄이기 위해 각 파라미터들을 조정하는 것이 딥러닝의 전체적인 학습 흐름이다.\n",
    "- 이 차이를 구하는 데 사용되는 함수는 손실함수(Loss function) 또는 비용함수(Cost function)라고 부른다. 대표적으로 다음과 같은 두 가지 손실함수가 존재한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d3d7b6",
   "metadata": {},
   "source": [
    "#### 평균제곱오차 (MSE:Mean Square Error)\n",
    "$$ \\dfrac{1}{n}\\sum ^{n}_{i=1}\\left( Y,-\\widehat{Y}_{i}\\right) ^{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff4db7e",
   "metadata": {},
   "source": [
    "#### 교차 엔트로피\n",
    "- 두 확률분포 사이의 유사도가 클수록 작아지는 값이다.\n",
    "$$ -\\sum ^{n}_{i=1}t_{i}\\log y_{i} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dfbbc97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답 라벨을 One-hot 인코딩하는 함수\n",
    "def _change_one_hot_label(X, num_category):\n",
    "    T = np.zeros((X.size, num_category))\n",
    "    for idx, row in enumerate(T):\n",
    "        row[X[idx]] = 1\n",
    "        \n",
    "    return T\n",
    "\n",
    "Y_digit = y_train[:5]\n",
    "t = _change_one_hot_label(Y_digit, 10)\n",
    "t     # 정답 라벨의 One-hot 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea8c9eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06274912 0.17464268 0.11735122 0.07784502 0.14061344 0.10427255\n",
      " 0.04898797 0.10180319 0.11959193 0.05214288]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_hat[0])\n",
    "print(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6eabeb72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2247689953809298"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size\n",
    "\n",
    "Loss = cross_entropy_error(y_hat, t)\n",
    "Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17abc92",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe382fac",
   "metadata": {},
   "source": [
    "## 18.4 경사하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c3c426",
   "metadata": {},
   "source": [
    "### 경사하강법\n",
    "- 각 단계에서의 기울기를 구해서 해당 기울기가 가리키는 방향으로 이동하는 방법\n",
    "- https://angeloyeo.github.io/2020/08/16/gradient_descent.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0448ade6",
   "metadata": {},
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/f-14v3-3-1.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a677462",
   "metadata": {},
   "source": [
    "- 위의 이미지처럼 각 시점의 기울기가 가리키는 방향으로 이동해나가는 것이다.\n",
    "### 학습률\n",
    "- 너무 크게 발걸음을 내디딜 수 있는 거인이라면 아마도 산 아래로 내려가지 못하고 또 다른 골짜기에 빠지고 말 것이다. 그래서 학습률(learning rate)라는 개념을 도입해 기울기 값과 이 학습률을 곱한 만큼만 발걸음을 내딛는다\n",
    "- https://aileen93.tistory.com/71\n",
    "\n",
    "### parameter의 값들을 초기화\n",
    "- 아무리 발걸음을 잘 내디딘다고 해도 어디서 출발했느냐에 따라 산 아래로 내려가는 시간이 빨라질 수도 느려질 수도 있다\n",
    "- 이는 parameter의 값들을 어떻게 초기화하는지의 문제와 맞닿아 있다\n",
    "- https://reniew.github.io/13/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdb3c1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01254982,  0.03492854,  0.02347024,  0.015569  ,  0.02812269,\n",
       "        -0.17914549,  0.00979759,  0.02036064,  0.02391839,  0.01042858],\n",
       "       [-0.18709704,  0.03128488,  0.02666148,  0.01462727,  0.02292979,\n",
       "         0.02382071,  0.01194104,  0.01706035,  0.02758347,  0.01118805],\n",
       "       [ 0.01319411,  0.03426455,  0.02228351,  0.01479392, -0.17058071,\n",
       "         0.02149948,  0.01189237,  0.0166717 ,  0.0225049 ,  0.01347615],\n",
       "       [ 0.01153027, -0.1592123 ,  0.02126317,  0.01353548,  0.02834575,\n",
       "         0.02070826,  0.01047444,  0.0144693 ,  0.02443853,  0.01444709],\n",
       "       [ 0.01575   ,  0.03181387,  0.02082753,  0.01436621,  0.02353015,\n",
       "         0.02853647,  0.00938121,  0.0179983 ,  0.02317197, -0.18537571]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_num = y_hat.shape[0]\n",
    "dy = (y_hat - t) / batch_num\n",
    "dy    # softmax값의 출력으로 Loss를 미분한 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27fe2ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.99226801e-02, -1.54248918e-02,  6.39627561e-02,\n",
       "         4.07376314e-02, -5.85561048e-02, -5.25668559e-02,\n",
       "         3.00643558e-02,  4.82221318e-02,  6.76990512e-02,\n",
       "        -5.42153938e-02],\n",
       "       [-6.77481352e-02, -2.20464141e-02,  4.72642515e-02,\n",
       "         2.98502352e-02, -1.64450681e-02, -2.98241654e-02,\n",
       "         2.20319886e-02,  3.53092181e-02,  5.03131528e-02,\n",
       "        -4.87050632e-02],\n",
       "       [-1.79722509e-02, -8.93895787e-02,  4.18536321e-02,\n",
       "         2.68584933e-02,  6.39609928e-04, -1.67403343e-02,\n",
       "         1.97803515e-02,  3.12080139e-02,  4.55224310e-02,\n",
       "        -4.17603680e-02],\n",
       "       [-8.00850684e-02,  2.01267496e-02,  5.13623428e-02,\n",
       "         3.25054031e-02, -4.93849759e-02, -2.40630556e-02,\n",
       "         2.40488731e-02,  3.86658542e-02,  5.41555837e-02,\n",
       "        -6.73317066e-02],\n",
       "       [-9.65070814e-02, -2.45322751e-02,  6.75191021e-02,\n",
       "         4.27181534e-02, -1.44739526e-02, -3.83934582e-02,\n",
       "         3.13665624e-02,  5.06986670e-02,  7.19884926e-02,\n",
       "        -9.03842102e-02],\n",
       "       [-9.93946138e-02, -1.07963964e-03,  6.25062174e-02,\n",
       "         3.94950866e-02,  1.33807736e-02, -5.89643780e-02,\n",
       "         2.85783627e-02,  4.74574495e-02,  6.65088713e-02,\n",
       "        -9.84881297e-02],\n",
       "       [-3.52534345e-02, -2.84809657e-02,  5.02029666e-02,\n",
       "         3.21718631e-02, -6.82239040e-02, -4.29844153e-02,\n",
       "         2.39020336e-02,  3.77787077e-02,  5.31269205e-02,\n",
       "        -2.22397721e-02],\n",
       "       [-8.93318877e-02, -1.13122042e-02,  5.28307414e-02,\n",
       "         3.31348261e-02, -2.09515520e-02, -5.59925173e-02,\n",
       "         2.44933958e-02,  3.93509089e-02,  5.57924686e-02,\n",
       "        -2.80141796e-02],\n",
       "       [-1.94390268e-02, -3.76350396e-02,  4.99328896e-02,\n",
       "         3.23399975e-02, -3.45425379e-02, -2.98641310e-02,\n",
       "         2.35556157e-02,  3.82311095e-02,  5.35268703e-02,\n",
       "        -7.61057473e-02],\n",
       "       [-1.44627622e-02, -6.24618597e-02,  4.19299757e-02,\n",
       "         2.70683126e-02, -5.05193746e-03, -3.06225707e-02,\n",
       "         1.96866403e-02,  3.18475824e-02,  4.53113373e-02,\n",
       "        -5.32447183e-02],\n",
       "       [-7.87658341e-02, -1.31927237e-02,  6.74201860e-02,\n",
       "         4.29241672e-02, -3.02866007e-02, -6.40073424e-02,\n",
       "         3.13358484e-02,  5.11607368e-02,  7.15565007e-02,\n",
       "        -7.81449382e-02],\n",
       "       [-8.23698449e-02, -8.44539310e-03,  6.30049180e-02,\n",
       "         3.99157606e-02, -2.64345914e-02, -8.71876882e-02,\n",
       "         2.91416518e-02,  4.76990122e-02,  6.65118574e-02,\n",
       "        -4.18356824e-02],\n",
       "       [-8.30645742e-02,  3.54994778e-02,  5.77519245e-02,\n",
       "         3.66441591e-02, -7.81196875e-02, -4.37316836e-02,\n",
       "         2.71383785e-02,  4.36555448e-02,  6.04788754e-02,\n",
       "        -5.62524149e-02],\n",
       "       [-1.28023816e-01, -2.82465781e-02,  6.55751088e-02,\n",
       "         4.09484810e-02,  4.01214732e-02, -5.55553202e-02,\n",
       "         2.98736298e-02,  4.89155797e-02,  7.00296326e-02,\n",
       "        -8.36381904e-02],\n",
       "       [-6.11680614e-02,  2.38939991e-02,  4.57431480e-02,\n",
       "         2.90414283e-02, -2.65359497e-02, -8.68988714e-02,\n",
       "         2.09905030e-02,  3.51259993e-02,  4.78184624e-02,\n",
       "        -2.80106576e-02],\n",
       "       [-1.07298357e-01,  1.85226074e-02,  5.11666908e-02,\n",
       "         3.18624831e-02, -3.56837110e-02, -4.73991230e-02,\n",
       "         2.37316910e-02,  3.79264090e-02,  5.36110512e-02,\n",
       "        -2.64397411e-02],\n",
       "       [-8.41145199e-02,  1.80891824e-02,  6.16662010e-02,\n",
       "         3.91377065e-02, -6.86323054e-02, -4.68937903e-02,\n",
       "         2.89377877e-02,  4.65320717e-02,  6.48704384e-02,\n",
       "        -5.95927721e-02],\n",
       "       [-6.47035534e-02, -1.81477651e-02,  4.26915208e-02,\n",
       "         2.69106863e-02, -4.57221612e-03, -3.69312149e-02,\n",
       "         1.97538483e-02,  3.19733977e-02,  4.54160397e-02,\n",
       "        -4.23907433e-02],\n",
       "       [-1.10247021e-01, -3.40396948e-02,  7.70947899e-02,\n",
       "         4.86779342e-02,  1.61669660e-02, -1.02700113e-01,\n",
       "         3.53180704e-02,  5.82449376e-02,  8.19814990e-02,\n",
       "        -7.04973680e-02],\n",
       "       [-8.58241525e-02,  1.71669612e-03,  6.06296616e-02,\n",
       "         3.85036129e-02, -4.01481593e-03, -4.32540222e-02,\n",
       "         2.79278104e-02,  4.61484915e-02,  6.45529032e-02,\n",
       "        -1.06386185e-01],\n",
       "       [-4.49865844e-02, -1.32934942e-02,  4.11998028e-02,\n",
       "         2.62638184e-02, -2.29074079e-02, -3.22519035e-02,\n",
       "         1.92448532e-02,  3.11823329e-02,  4.38018935e-02,\n",
       "        -4.82533109e-02],\n",
       "       [-6.97318459e-02,  1.10059072e-02,  7.33963280e-02,\n",
       "         4.71184059e-02, -7.48110840e-02, -4.01839538e-02,\n",
       "         3.45059063e-02,  5.60811097e-02,  7.77739088e-02,\n",
       "        -1.15154682e-01],\n",
       "       [-4.08367645e-02,  1.29264254e-02,  4.66227007e-02,\n",
       "         3.00522569e-02, -6.94134109e-03, -5.48868573e-02,\n",
       "         2.13933741e-02,  3.63864526e-02,  4.95550748e-02,\n",
       "        -9.42713215e-02],\n",
       "       [-2.57646592e-02, -1.15349604e-02,  7.50179328e-02,\n",
       "         4.87747364e-02, -4.97017931e-02, -9.40371853e-02,\n",
       "         3.49654832e-02,  5.85139621e-02,  7.97664317e-02,\n",
       "        -1.15999948e-01],\n",
       "       [-5.65111546e-02,  6.92351334e-03,  6.40441595e-02,\n",
       "         4.12131239e-02, -6.12565197e-02, -2.44771395e-02,\n",
       "         3.01248657e-02,  4.90412893e-02,  6.80689772e-02,\n",
       "        -1.17171115e-01],\n",
       "       [-1.16181606e-01,  7.93646962e-04,  6.80308389e-02,\n",
       "         4.28001393e-02, -2.22015047e-02, -4.92975593e-02,\n",
       "         3.14976089e-02,  5.09863222e-02,  7.20516434e-02,\n",
       "        -7.84795300e-02],\n",
       "       [-6.94747194e-02, -5.07601227e-02,  7.47430156e-02,\n",
       "         4.76598905e-02, -8.99243923e-02, -3.26437223e-02,\n",
       "         3.56168440e-02,  5.57258317e-02,  7.94272721e-02,\n",
       "        -5.03698972e-02],\n",
       "       [-5.25878954e-03, -7.34989925e-02,  5.23359716e-02,\n",
       "         3.39541612e-02, -3.07144439e-02, -4.66162543e-02,\n",
       "         2.47640271e-02,  3.98907149e-02,  5.62990480e-02,\n",
       "        -5.11554424e-02],\n",
       "       [-6.70777325e-02,  3.88250558e-02,  6.49001011e-02,\n",
       "         4.17228684e-02, -8.36808333e-02, -1.92891227e-02,\n",
       "         3.05881426e-02,  4.97827756e-02,  6.85632968e-02,\n",
       "        -1.24334552e-01],\n",
       "       [-4.86577453e-02,  2.91604219e-02,  4.02552358e-02,\n",
       "         2.57812279e-02, -1.39518805e-02, -5.04751778e-02,\n",
       "         1.84370919e-02,  3.13103725e-02,  4.24630932e-02,\n",
       "        -7.43226396e-02],\n",
       "       [-5.65744208e-02, -7.46148454e-03,  4.01721119e-02,\n",
       "         2.54857921e-02, -2.79986920e-02,  3.02079116e-03,\n",
       "         1.89069763e-02,  3.00564385e-02,  4.28584277e-02,\n",
       "        -6.84659405e-02],\n",
       "       [-9.15102808e-02,  2.46405601e-02,  5.76818243e-02,\n",
       "         3.63603083e-02, -8.52637198e-02, -4.82880216e-02,\n",
       "         2.72079052e-02,  4.30625652e-02,  6.02481513e-02,\n",
       "        -2.41392921e-02],\n",
       "       [-6.43137080e-02,  5.28225624e-04,  5.40091553e-02,\n",
       "         3.44138050e-02, -5.61537469e-02, -2.35553420e-02,\n",
       "         2.54533106e-02,  4.07372098e-02,  5.71940855e-02,\n",
       "        -6.83129950e-02],\n",
       "       [-6.50399922e-02,  1.63156414e-02,  4.98507415e-02,\n",
       "         3.17493325e-02, -2.29084597e-02, -5.09538888e-02,\n",
       "         2.30249867e-02,  3.81610485e-02,  5.26862251e-02,\n",
       "        -7.28856350e-02],\n",
       "       [-3.30694746e-02, -7.12540213e-02,  4.16822842e-02,\n",
       "         2.65172352e-02,  1.16258777e-02, -5.16428487e-02,\n",
       "         1.93671444e-02,  3.11951282e-02,  4.48786250e-02,\n",
       "        -1.92999502e-02],\n",
       "       [-9.78770907e-02,  2.10185391e-02,  6.83744364e-02,\n",
       "         4.32492738e-02, -5.17792864e-02, -1.04348161e-01,\n",
       "         3.16545661e-02,  5.18509487e-02,  7.16115731e-02,\n",
       "        -3.37547993e-02],\n",
       "       [-4.51416719e-02,  6.64222731e-03,  3.46371136e-02,\n",
       "         2.21124074e-02, -3.13320834e-02,  1.09663395e-02,\n",
       "         1.63376137e-02,  2.61771932e-02,  3.69344724e-02,\n",
       "        -7.73336119e-02],\n",
       "       [-8.04843815e-02, -2.62877489e-02,  6.74348645e-02,\n",
       "         4.26900109e-02, -8.74303993e-02, -6.36800406e-02,\n",
       "         3.19612184e-02,  5.01329884e-02,  7.09884740e-02,\n",
       "        -5.32498592e-03],\n",
       "       [-2.36226909e-02, -1.98312595e-02,  5.85037617e-02,\n",
       "         3.79599072e-02, -7.60611977e-03, -8.72173980e-02,\n",
       "         2.69699615e-02,  4.57303492e-02,  6.24244271e-02,\n",
       "        -9.33109386e-02],\n",
       "       [-5.77326126e-02,  2.55609928e-02,  4.41909504e-02,\n",
       "         2.82253762e-02, -2.35601473e-02, -3.31618112e-02,\n",
       "         2.04291095e-02,  3.39948704e-02,  4.67411549e-02,\n",
       "        -8.46878831e-02],\n",
       "       [-8.68170087e-02, -2.32617690e-02,  7.19654570e-02,\n",
       "         4.57677579e-02,  2.82200865e-03, -8.43815716e-02,\n",
       "         3.30957650e-02,  5.48154780e-02,  7.66196786e-02,\n",
       "        -9.06257959e-02],\n",
       "       [-4.83910836e-02, -1.38442572e-02,  4.10906223e-02,\n",
       "         2.61152616e-02, -7.79617649e-02,  1.77821293e-02,\n",
       "         1.99065447e-02,  3.02355682e-02,  4.35603396e-02,\n",
       "        -3.84933600e-02],\n",
       "       [-1.12095450e-01,  2.80697097e-02,  7.61108765e-02,\n",
       "         4.82130188e-02, -5.86398067e-02, -7.49322189e-02,\n",
       "         3.53682758e-02,  5.76691841e-02,  8.00761013e-02,\n",
       "        -7.98396902e-02],\n",
       "       [-1.04805126e-01, -1.49944191e-02,  5.20763079e-02,\n",
       "         3.23814818e-02, -5.30232414e-02, -7.99482195e-03,\n",
       "         2.46342834e-02,  3.77881479e-02,  5.49856162e-02,\n",
       "        -2.10482283e-02],\n",
       "       [-3.27188784e-02, -2.30422113e-02,  5.03329379e-02,\n",
       "         3.24035317e-02, -6.04514262e-02, -2.22029476e-02,\n",
       "         2.39360275e-02,  3.81391142e-02,  5.35659039e-02,\n",
       "        -5.99620517e-02],\n",
       "       [-9.62968977e-02, -3.25754188e-02,  6.36231636e-02,\n",
       "         4.01136840e-02, -1.69189053e-03, -4.55943801e-02,\n",
       "         2.94517472e-02,  4.75981953e-02,  6.78629942e-02,\n",
       "        -7.24911972e-02],\n",
       "       [-1.04773604e-01, -2.63913495e-02,  5.16362302e-02,\n",
       "         3.21849955e-02, -1.27532345e-02,  1.41128971e-02,\n",
       "         2.41784367e-02,  3.76994093e-02,  5.52303381e-02,\n",
       "        -7.11241188e-02],\n",
       "       [-8.57085801e-02, -6.76253871e-02,  4.40872062e-02,\n",
       "         2.73069013e-02,  1.06498700e-05,  3.43177562e-03,\n",
       "         2.07385499e-02,  3.15349737e-02,  4.74251801e-02,\n",
       "        -2.12012693e-02],\n",
       "       [-1.37717484e-01,  4.09417741e-02,  8.04315472e-02,\n",
       "         5.07667645e-02, -3.82133671e-02, -6.46422172e-02,\n",
       "         3.71286516e-02,  6.09264057e-02,  8.48047258e-02,\n",
       "        -1.14426800e-01],\n",
       "       [-1.23875947e-01,  7.52037158e-03,  6.52752793e-02,\n",
       "         4.08529345e-02, -1.95529039e-02, -6.15610120e-02,\n",
       "         3.01110175e-02,  4.87521205e-02,  6.88614269e-02,\n",
       "        -5.63832874e-02]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW2 = np.dot(z1.T, dy)    \n",
    "dW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16527c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dW2 = np.dot(z1.T, dy)\n",
    "db2 = np.sum(dy, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecf3538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid가 한번 사용되었으므로, 활성화함수에 대한 gradient도 고려되어야 한다\n",
    "def sigmoid_grad(x):\n",
    "    return (1.0 - sigmoid(x)) * sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce73ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz1 = np.dot(dy, W2.T)\n",
    "da1 = sigmoid_grad(a1) * dz1\n",
    "dW1 = np.dot(X.T, da1)\n",
    "db1 = np.sum(dz1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48065894",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
    "    W1 = W1 - learning_rate*dW1\n",
    "    b1 = b1 - learning_rate*db1\n",
    "    W2 = W2 - learning_rate*dW2\n",
    "    b2 = b2 - learning_rate*db2\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d792dfb4",
   "metadata": {},
   "source": [
    "## 18.5 오차역전파법이란?\n",
    "- 오차역전파법은 앞에서 설명한 MLP를 학습시키기 위한 일반적인 알고리즘 중 하나\n",
    "- 이는 출력층의 결과와 내가 뽑고자 하는 target 값과의 차이를 구한 뒤, 그 오차 값을 각 레이어들을 지나며 역전파 해가며 각 노드가 가지고 있는 변수들을 갱신해 나가는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26fa1eb",
   "metadata": {},
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/f-14-6.max-800x600.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "627316ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_layer_backward(dy, cache):\n",
    "    X, W, b = cache\n",
    "    dX = np.dot(dy, W.T)\n",
    "    dW = np.dot(X.T, dy)\n",
    "    db = np.sum(dy, axis=0)\n",
    "    return dX, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12cc436e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07743927 0.08089628 0.09629717 0.16421578 0.11196955 0.11112861\n",
      "  0.05514635 0.07922406 0.14635767 0.07732525]\n",
      " [0.06866527 0.08043419 0.09027906 0.1665992  0.10671759 0.15562449\n",
      "  0.06409697 0.08434271 0.12596228 0.05727824]\n",
      " [0.07676784 0.07785074 0.06443504 0.16933535 0.12990645 0.15789962\n",
      "  0.06577633 0.08221603 0.10245283 0.07335977]\n",
      " [0.07961613 0.05818946 0.08039585 0.14323694 0.11976965 0.16768608\n",
      "  0.05747565 0.10344012 0.11986815 0.07032198]\n",
      " [0.0913858  0.06724031 0.09620549 0.14062306 0.09851724 0.14696265\n",
      "  0.05637197 0.09335199 0.14199862 0.06734286]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.4917057802917046\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 초기화\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "# Forward Propagation\n",
    "a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "z1 = sigmoid(a1)\n",
    "a2, cache2 = affine_layer_forward(z1, W2, b2)\n",
    "\n",
    "# 추론과 오차(Loss) 계산\n",
    "y_hat = softmax(a2)\n",
    "t = _change_one_hot_label(Y_digit, 10)   # 정답 One-hot 인코딩\n",
    "Loss = cross_entropy_error(y_hat, t)\n",
    "\n",
    "print(y_hat)\n",
    "print(t)\n",
    "print('Loss: ', Loss)\n",
    "        \n",
    "dy = (y_hat - t) / X.shape[0]\n",
    "dz1, dW2, db2 = affine_layer_backward(dy, cache2)\n",
    "da1 = sigmoid_grad(a1) * dz1\n",
    "dX, dW1, db1 = affine_layer_backward(da1, cache1)\n",
    "\n",
    "# 경사하강법을 통한 파라미터 업데이트    \n",
    "learning_rate = 0.1\n",
    "W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b06b76",
   "metadata": {},
   "source": [
    "## 18.6 모델 학습 Step-by-Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e73a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "def train_step(X, Y, W1, b1, W2, b2, learning_rate=0.1, verbose=False):\n",
    "    a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "    z1 = sigmoid(a1)\n",
    "    a2, cache2 = affine_layer_forward(z1, W2, b2)\n",
    "    y_hat = softmax(a2)\n",
    "    t = _change_one_hot_label(Y, 10)\n",
    "    Loss = cross_entropy_error(y_hat, t)\n",
    "\n",
    "    if verbose:\n",
    "        print('---------')\n",
    "        print(y_hat)\n",
    "        print(t)\n",
    "        print('Loss: ', Loss)\n",
    "        \n",
    "    dy = (y_hat - t) / X.shape[0]\n",
    "    dz1, dW2, db2 = affine_layer_backward(dy, cache2)\n",
    "    da1 = sigmoid_grad(a1) * dz1\n",
    "    dX, dW1, db1 = affine_layer_backward(da1, cache1)\n",
    "    \n",
    "    W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)\n",
    "    \n",
    "    return W1, b1, W2, b2, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7978ef34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "[[0.08067246 0.08472299 0.02949138 0.16927606 0.12692501 0.05811663\n",
      "  0.11723316 0.07438501 0.12381873 0.13535857]\n",
      " [0.08224365 0.07634319 0.03625898 0.15068707 0.11378039 0.05532762\n",
      "  0.13662792 0.08600952 0.10438591 0.15833574]\n",
      " [0.07521739 0.08128656 0.04250698 0.16621149 0.12422436 0.07398249\n",
      "  0.11594734 0.07819709 0.10629807 0.13612821]\n",
      " [0.07341484 0.08657169 0.0330716  0.17598463 0.10476333 0.0674031\n",
      "  0.11272376 0.08089163 0.14197058 0.12320483]\n",
      " [0.06129492 0.07129893 0.03399943 0.13238228 0.13677606 0.09045191\n",
      "  0.15938002 0.08338588 0.09159968 0.13943089]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.369201453640305\n",
      "---------\n",
      "[[0.0969725  0.10249744 0.02875021 0.1361855  0.14122862 0.07478008\n",
      "  0.09877246 0.06770882 0.10539334 0.14771103]\n",
      " [0.10373009 0.09020918 0.03551388 0.12216291 0.12489668 0.0674332\n",
      "  0.11477521 0.07854528 0.08935856 0.17337499]\n",
      " [0.08818786 0.0947056  0.04086581 0.13610212 0.14337228 0.0889295\n",
      "  0.09864633 0.07071157 0.09152018 0.14695875]\n",
      " [0.08802051 0.10823752 0.03228151 0.14357865 0.11619167 0.08333331\n",
      "  0.09576007 0.07410724 0.12316987 0.13531966]\n",
      " [0.07326524 0.08420495 0.03270921 0.10745646 0.14959907 0.10846168\n",
      "  0.13377992 0.07533867 0.07872385 0.15646095]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.175970698937835\n",
      "---------\n",
      "[[0.11102695 0.11804026 0.02734691 0.11207737 0.15063289 0.09158369\n",
      "  0.08385153 0.06086189 0.08992097 0.15465755]\n",
      " [0.12506264 0.10180836 0.03400008 0.10141066 0.13180092 0.07847205\n",
      "  0.09725068 0.07093382 0.07680269 0.1824581 ]\n",
      " [0.09931867 0.10591614 0.03855687 0.11380931 0.15960242 0.10267516\n",
      "  0.08460742 0.06334673 0.07902155 0.15314572]\n",
      " [0.10069896 0.12901833 0.03076298 0.11947244 0.1235723  0.09825821\n",
      "  0.08178744 0.066994   0.10691066 0.14252467]\n",
      " [0.08404728 0.0953117  0.03087166 0.08923468 0.15781204 0.12479346\n",
      "  0.11336827 0.06744402 0.06793085 0.16918604]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.025813857961946\n",
      "---------\n",
      "[[0.12276667 0.13122627 0.02566849 0.09397167 0.1564728  0.10815957\n",
      "  0.07191328 0.0545205  0.07726451 0.15803625]\n",
      " [0.1459412  0.11113693 0.03214182 0.08577757 0.13565487 0.08823583\n",
      "  0.08325907 0.06386397 0.06650559 0.18748316]\n",
      " [0.10860115 0.1149584  0.03602735 0.09683388 0.17365974 0.11501144\n",
      "  0.07330017 0.05664787 0.06869037 0.15626963]\n",
      " [0.11133785 0.14854738 0.02892694 0.10106579 0.12794166 0.11183994\n",
      "  0.07043223 0.06029739 0.093292   0.14631883]\n",
      " [0.09357995 0.10460258 0.02885339 0.07549639 0.16276163 0.13924022\n",
      "  0.09716854 0.06028772 0.05907313 0.17893644]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  1.9053864960573752\n",
      "---------\n",
      "[[0.13229327 0.14214889 0.02393176 0.08003549 0.15989192 0.12423561\n",
      "  0.06233344 0.04889864 0.06696919 0.15926179]\n",
      " [0.16618776 0.11834565 0.03018171 0.07367195 0.13741912 0.09661617\n",
      "  0.07201902 0.05755379 0.05807345 0.18993138]\n",
      " [0.11612469 0.12200171 0.03351636 0.08360955 0.1862782  0.1258263\n",
      "  0.0641579  0.05076072 0.0601916  0.15753296]\n",
      " [0.12000161 0.16670491 0.0270129  0.08671699 0.1302277  0.12389905\n",
      "  0.06120831 0.05428859 0.08200188 0.14793806]\n",
      " [0.10188514 0.11218783 0.02685061 0.06488237 0.16555033 0.1517152\n",
      "  0.08424135 0.0540225  0.05183157 0.1868331 ]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  1.805959230528638\n"
     ]
    }
   ],
   "source": [
    "X = x_train_reshaped[:5]\n",
    "Y = y_train[:5]\n",
    "\n",
    "# train_step을 다섯 번 반복 돌립니다.\n",
    "for i in range(5):\n",
    "    W1, b1, W2, b2, _ = train_step(X, Y, W1, b1, W2, b2, learning_rate=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6ecfb8",
   "metadata": {},
   "source": [
    "## 18.7 추론 과정 구현과 정확도(Accuracy) 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa3a44f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W1, b1, W2, b2, X):\n",
    "    a1 = np.dot(X, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    y = softmax(a2)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc89c763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13980265, 0.15102854, 0.02225038, 0.06908724, 0.16174057,\n",
       "       0.13963183, 0.05458597, 0.0440118 , 0.05857079, 0.15929024])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = x_train[:100] 에 대해 모델 추론을 시도합니다. \n",
    "X = x_train_reshaped[:100]\n",
    "Y = y_test[:100]\n",
    "result = predict(W1, b1, W2, b2, X)\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6dfb4030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(W1, b1, W2, b2, x, y):\n",
    "    y_hat = predict(W1, b1, W2, b2, x)\n",
    "    y_hat = np.argmax(y_hat, axis=1)\n",
    "\n",
    "    accuracy = np.sum(y_hat == y) / float(x.shape[0])\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de2718ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13980265 0.15102854 0.02225038 0.06908724 0.16174057 0.13963183\n",
      " 0.05458597 0.0440118  0.05857079 0.15929024]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "0.04\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy(W1, b1, W2, b2, X, Y)\n",
    "\n",
    "t = _change_one_hot_label(Y, 10)\n",
    "print(result[0])\n",
    "print(t[0])\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb169964",
   "metadata": {},
   "source": [
    "## 18.8 전체 학습 사이클 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d2d8736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "\n",
    "    W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "    b1 = np.zeros(hidden_size)\n",
    "    W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "    b2 = np.zeros(output_size)\n",
    "\n",
    "    print(W1.shape)\n",
    "    print(b1.shape)\n",
    "    print(W2.shape)\n",
    "    print(b2.shape)\n",
    "    \n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "918e2de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50)\n",
      "(50,)\n",
      "(50, 10)\n",
      "(10,)\n",
      "Loss:  2.3019526596358\n",
      "train acc, test acc | 0.0993, 0.1032\n",
      "Loss:  0.8664451754439207\n",
      "train acc, test acc | 0.7813333333333333, 0.7912\n",
      "Loss:  0.5137265350661644\n",
      "train acc, test acc | 0.8791166666666667, 0.8844\n",
      "Loss:  0.5171094064406803\n",
      "train acc, test acc | 0.89885, 0.9033\n",
      "Loss:  0.2908570721916075\n",
      "train acc, test acc | 0.9084833333333333, 0.9122\n",
      "Loss:  0.3232795332144903\n",
      "train acc, test acc | 0.9147, 0.9167\n",
      "Loss:  0.29947753870768024\n",
      "train acc, test acc | 0.9209333333333334, 0.9235\n",
      "Loss:  0.27873668198584406\n",
      "train acc, test acc | 0.9239166666666667, 0.9252\n",
      "Loss:  0.2898946738505911\n",
      "train acc, test acc | 0.9280666666666667, 0.9296\n",
      "Loss:  0.20341726206129093\n",
      "train acc, test acc | 0.9318666666666666, 0.933\n",
      "Loss:  0.18259555099715744\n",
      "train acc, test acc | 0.9346, 0.9344\n",
      "Loss:  0.18171235786937148\n",
      "train acc, test acc | 0.93735, 0.9371\n",
      "Loss:  0.1459433111302474\n",
      "train acc, test acc | 0.9400166666666666, 0.9402\n",
      "Loss:  0.21348909046768502\n",
      "train acc, test acc | 0.9426333333333333, 0.9403\n",
      "Loss:  0.14887220026334633\n",
      "train acc, test acc | 0.94475, 0.9437\n",
      "Loss:  0.10085584961855279\n",
      "train acc, test acc | 0.9458833333333333, 0.945\n",
      "Loss:  0.2196723658828427\n",
      "train acc, test acc | 0.9479333333333333, 0.9468\n",
      "Loss:  0.1528552958778989\n",
      "train acc, test acc | 0.9494166666666667, 0.9477\n",
      "Loss:  0.30484428588403095\n",
      "train acc, test acc | 0.9510666666666666, 0.9499\n",
      "Loss:  0.18712578063953766\n",
      "train acc, test acc | 0.95225, 0.95\n",
      "Loss:  0.1584475265406733\n",
      "train acc, test acc | 0.9534833333333333, 0.951\n",
      "Loss:  0.08461722417122206\n",
      "train acc, test acc | 0.9546, 0.9522\n",
      "Loss:  0.15541031959404145\n",
      "train acc, test acc | 0.9561166666666666, 0.9539\n",
      "Loss:  0.13415793409828736\n",
      "train acc, test acc | 0.9563833333333334, 0.9545\n",
      "Loss:  0.14794881959908351\n",
      "train acc, test acc | 0.95785, 0.955\n",
      "Loss:  0.11396871756615354\n",
      "train acc, test acc | 0.95865, 0.9557\n",
      "Loss:  0.08397355806224656\n",
      "train acc, test acc | 0.96005, 0.957\n",
      "Loss:  0.2051208112597479\n",
      "train acc, test acc | 0.9608666666666666, 0.9562\n",
      "Loss:  0.07784017230792395\n",
      "train acc, test acc | 0.9617666666666667, 0.9574\n",
      "Loss:  0.14989445091521741\n",
      "train acc, test acc | 0.9623666666666667, 0.9581\n",
      "Loss:  0.12086929221851327\n",
      "train acc, test acc | 0.9637833333333333, 0.9582\n",
      "Loss:  0.10500892367406989\n",
      "train acc, test acc | 0.96465, 0.9592\n",
      "Loss:  0.051699451242634475\n",
      "train acc, test acc | 0.9653666666666667, 0.9598\n",
      "Loss:  0.1746103025932937\n",
      "train acc, test acc | 0.96615, 0.9606\n",
      "Loss:  0.2038827067844106\n",
      "train acc, test acc | 0.9667166666666667, 0.9601\n",
      "Loss:  0.05575664277861441\n",
      "train acc, test acc | 0.9675666666666667, 0.9616\n",
      "Loss:  0.18682468300021265\n",
      "train acc, test acc | 0.9676, 0.9615\n",
      "Loss:  0.15276281058873484\n",
      "train acc, test acc | 0.96865, 0.9623\n",
      "Loss:  0.07636066480500779\n",
      "train acc, test acc | 0.9693, 0.9623\n",
      "Loss:  0.0676215346750063\n",
      "train acc, test acc | 0.9696166666666667, 0.9625\n",
      "Loss:  0.09569996394029295\n",
      "train acc, test acc | 0.9707833333333333, 0.9626\n",
      "Loss:  0.10371917148024283\n",
      "train acc, test acc | 0.9711, 0.9633\n",
      "Loss:  0.0892906427925641\n",
      "train acc, test acc | 0.9712, 0.9648\n",
      "Loss:  0.03361682719084999\n",
      "train acc, test acc | 0.9718, 0.9633\n",
      "Loss:  0.16411643554367086\n",
      "train acc, test acc | 0.9716666666666667, 0.9644\n",
      "Loss:  0.0798858835596155\n",
      "train acc, test acc | 0.9725166666666667, 0.9651\n",
      "Loss:  0.037700513262391946\n",
      "train acc, test acc | 0.9732666666666666, 0.9643\n",
      "Loss:  0.11872638330534095\n",
      "train acc, test acc | 0.9738, 0.9646\n",
      "Loss:  0.13356432640863378\n",
      "train acc, test acc | 0.9739166666666667, 0.9645\n",
      "Loss:  0.058647358300427437\n",
      "train acc, test acc | 0.9742666666666666, 0.9662\n",
      "Loss:  0.1134978505807927\n",
      "train acc, test acc | 0.9747833333333333, 0.9658\n",
      "Loss:  0.09938281978718189\n",
      "train acc, test acc | 0.9747, 0.9668\n",
      "Loss:  0.030122764681002417\n",
      "train acc, test acc | 0.9749333333333333, 0.966\n",
      "Loss:  0.09887665077239323\n",
      "train acc, test acc | 0.9752666666666666, 0.9674\n",
      "Loss:  0.04350401682442001\n",
      "train acc, test acc | 0.9759, 0.9669\n",
      "Loss:  0.10208084169451834\n",
      "train acc, test acc | 0.9765666666666667, 0.966\n",
      "Loss:  0.04817667624566611\n",
      "train acc, test acc | 0.9764666666666667, 0.9675\n",
      "Loss:  0.043965342610996314\n",
      "train acc, test acc | 0.97655, 0.9679\n",
      "Loss:  0.11346649252723334\n",
      "train acc, test acc | 0.9770833333333333, 0.9679\n",
      "Loss:  0.10467114465041037\n",
      "train acc, test acc | 0.9775166666666667, 0.9684\n",
      "Loss:  0.0796209008531098\n",
      "train acc, test acc | 0.9775, 0.9683\n",
      "Loss:  0.047330862713226\n",
      "train acc, test acc | 0.97785, 0.9686\n",
      "Loss:  0.054346002478844975\n",
      "train acc, test acc | 0.9784166666666667, 0.9689\n",
      "Loss:  0.09989563278252285\n",
      "train acc, test acc | 0.9788833333333333, 0.969\n",
      "Loss:  0.05601188732200935\n",
      "train acc, test acc | 0.9784666666666667, 0.9683\n",
      "Loss:  0.0527129881692908\n",
      "train acc, test acc | 0.9792666666666666, 0.9686\n",
      "Loss:  0.06363104283126231\n",
      "train acc, test acc | 0.9790833333333333, 0.9687\n",
      "Loss:  0.07847879205485518\n",
      "train acc, test acc | 0.9795166666666667, 0.9691\n",
      "Loss:  0.06556272789430148\n",
      "train acc, test acc | 0.97965, 0.9697\n",
      "Loss:  0.10340472690370892\n",
      "train acc, test acc | 0.97975, 0.9691\n",
      "Loss:  0.0555235200082719\n",
      "train acc, test acc | 0.9798, 0.9696\n",
      "Loss:  0.08910233598908304\n",
      "train acc, test acc | 0.9804166666666667, 0.9698\n",
      "Loss:  0.027792491576727432\n",
      "train acc, test acc | 0.9802, 0.9696\n",
      "Loss:  0.09403293207775557\n",
      "train acc, test acc | 0.98055, 0.9697\n",
      "Loss:  0.07836760346086297\n",
      "train acc, test acc | 0.9809333333333333, 0.9706\n",
      "Loss:  0.040102305759516635\n",
      "train acc, test acc | 0.9809, 0.9701\n",
      "Loss:  0.026748830683826715\n",
      "train acc, test acc | 0.98125, 0.9704\n",
      "Loss:  0.17703535463317122\n",
      "train acc, test acc | 0.9815833333333334, 0.9705\n",
      "Loss:  0.036926303385225456\n",
      "train acc, test acc | 0.9816166666666667, 0.9712\n",
      "Loss:  0.04264762643454449\n",
      "train acc, test acc | 0.9819666666666667, 0.9698\n",
      "Loss:  0.185710139424004\n",
      "train acc, test acc | 0.9826, 0.9707\n",
      "Loss:  0.09406739575757282\n",
      "train acc, test acc | 0.9824666666666667, 0.9702\n",
      "Loss:  0.033505251807978344\n",
      "train acc, test acc | 0.9824, 0.9709\n",
      "Loss:  0.10103453159182635\n",
      "train acc, test acc | 0.9826, 0.9709\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터\n",
    "iters_num = 50000  # 반복 횟수를 적절히 설정한다.\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100   # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "W1, b1, W2, b2 = init_params(784, 50, 10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train_reshaped[batch_mask]\n",
    "    y_batch = y_train[batch_mask]\n",
    "    \n",
    "    W1, b1, W2, b2, Loss = train_step(x_batch, y_batch, W1, b1, W2, b2, learning_rate=0.1, verbose=False)\n",
    "\n",
    "    # 학습 경과 기록\n",
    "    train_loss_list.append(Loss)\n",
    "    \n",
    "    # 1에폭당 정확도 계산\n",
    "    if i % iter_per_epoch == 0:\n",
    "        print('Loss: ', Loss)\n",
    "        train_acc = accuracy(W1, b1, W2, b2, x_train_reshaped, y_train)\n",
    "        test_acc = accuracy(W1, b1, W2, b2, x_test_reshaped, y_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f39415ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 6 \n",
    "\n",
    "# Accuracy 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb056d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss 그래프 그리기\n",
    "x = np.arange(len(train_loss_list))\n",
    "plt.plot(x, train_loss_list, label='train acc')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.ylim(0, 3.0)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
