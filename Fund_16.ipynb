{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c812da7",
   "metadata": {},
   "source": [
    "# < 21. TF2 API 개요 >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6e4c4c",
   "metadata": {},
   "source": [
    "## 학습목표\n",
    "- Tensorflow V2의 개요와 특징을 파악한다.\n",
    "- Tensorflow V2의 3가지 주요 API 구성 방식을 이해하고 활용할 수 있다.\n",
    "- GradientTape를 활용해 보고 좀 더 로우 레벨의 딥러닝 구현 방식을 이해한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5449e6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d61b2de",
   "metadata": {},
   "source": [
    "## 21.2 TensorFlow2 API로 모델 구성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bd4453",
   "metadata": {},
   "source": [
    "### TensorFlow2 API 알아보기\n",
    "- TensorFlow2에서 딥러닝 모델을 작성하는 방법에는 크게 3가지가 존재\n",
    "    1. Sequential\n",
    "    2. Functional\n",
    "    3. Model Subclassing\n",
    "- https://www.tensorflow.org/tutorials/quickstart/beginner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e87f4a",
   "metadata": {},
   "source": [
    "### 1) TensorFlow2 Sequential Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b84e9c6",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential() <br>\n",
    "model.add(__넣고싶은 레이어__) <br>\n",
    "model.add(__넣고싶은 레이어__) <br>\n",
    "model.add(__넣고싶은 레이어__)\n",
    "\n",
    "model.fit(x, y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6923a5ff",
   "metadata": {},
   "source": [
    "- 공부했던 모델은 대부분 위와 같은 형식\n",
    "- Sequential 모델을 활용하면 손쉽게 딥러닝 모델을 쌓아나갈 수 있다\n",
    "- 그렇지만 모델의 입력과 출력이 여러 개인 경우에는 적합하지 않은 모델링 방식입니다. Sequential 모델은 반드시 입력 1가지, 출력 1가지를 전제로 한다\n",
    "- https://www.tensorflow.org/guide/keras/functional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf43427",
   "metadata": {},
   "source": [
    "### 2) TensorFlow2 Functional API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb85f1a",
   "metadata": {},
   "source": [
    "import tensorflow as tf <br>\n",
    "from tensorflow import keras\n",
    "\n",
    "inputs = keras.Input(shape=(__원하는 입력값 모양__)) <br>\n",
    "x = keras.layers.\\__넣고싶은 레이어__(관련 파라미터)(input) <br>\n",
    "x = keras.layers.\\__넣고싶은 레이어__(관련 파라미터)(x) <br>\n",
    "outputs = keras.layers.\\__넣고싶은 레이어__(관련 파라미터)(x )\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs) <br>\n",
    "model.fit(x,y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744bd298",
   "metadata": {},
   "source": [
    "-  Sequential Model을 활용하는 것과 다른 점은 바로 keras.Model을 사용한다는 점\n",
    "- Functional API를 활용하면 앞서 배운 Sequential Model을 활용하는 것보다 더 자유로운 모델링을 진행할 수 있다\n",
    "- 입력과 출력을 규정함으로써 모델 전체를 규정한다\n",
    "- Functional API를 통해 다중 입력/출력을 가지는 모델을 구성할 수 있다\n",
    "- https://www.tensorflow.org/tutorials/quickstart/advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8cee92",
   "metadata": {},
   "source": [
    "### 3) TensorFlow2 Subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd291650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.__정의하고자 하는 레이어__()\n",
    "        self.__정의하고자 하는 레이어__()\n",
    "        self.__정의하고자 하는 레이어__()\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.__정의하고자 하는 레이어__(x)\n",
    "        x = self.__정의하고자 하는 레이어__(x)\n",
    "        x = self.__정의하고자 하는 레이어__(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = CustomModel()\n",
    "model.fit(x,y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a199ac3",
   "metadata": {},
   "source": [
    "- Subclassing을 활용하면 제일 자유로운 모델링을 진행할 수 있다\n",
    "- keras.Model은 위와 같이 \\__init__()이라는 메서드 안에서 레이어 구성을 정의\n",
    "- call()이라는 메서드 안에서 레이어 간 forward propagation을 구현\n",
    "- 다만, 각 레이어에 대한 깊은 이해가 필요하고 초심자에게 의도치 않은 버그를 유발할 수 있디"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b03ff9d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9a4ad0",
   "metadata": {},
   "source": [
    "## 21.3 Tensorflow2 API로 모델 작성하기: MNIST (1) Sequential API 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26f3709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b7418db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c80489a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "356e3423",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c182f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 30s 3ms/step - loss: 0.1032 - accuracy: 0.9683\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0361 - accuracy: 0.9889\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0210 - accuracy: 0.9934\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0140 - accuracy: 0.9958\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0101 - accuracy: 0.9966\n",
      "313/313 - 1s - loss: 0.0467 - accuracy: 0.9874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.046652812510728836, 0.9873999953269958]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba924801",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd11e92",
   "metadata": {},
   "source": [
    "## 21.4 Tensorflow2 API로 모델 작성하기: MNIST (2) Functional API 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3241fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3a9d023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d23ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = keras.layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "x = keras.layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(128, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dff3b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1070 - accuracy: 0.9677\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0343 - accuracy: 0.9893\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0205 - accuracy: 0.9932\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0130 - accuracy: 0.9958\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0102 - accuracy: 0.9966\n",
      "313/313 - 1s - loss: 0.0473 - accuracy: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04730531573295593, 0.987500011920929]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6747fc2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a853d166",
   "metadata": {},
   "source": [
    "## 21.5 Tensorflow2 API로 모델 작성하기 : MNIST (3) Subclassing 활용\n",
    "- keras.Model을 상속받은 클래스를 만드는 것\n",
    "- \\__init__() 메서드 안에서 레이어를 선언하고, call() 메서드 안에서 forward propagation을 구현하는 방식\n",
    "- Functional 방식과 비교하자면, call()의 입력이 Input이고, call()의 리턴값이 Output이 되는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6394092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d97e4c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b094cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.conv2 = keras.layers.Conv2D(64, 3, activation='relu')\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(128, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(10, activation='softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fee7d9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1065 - accuracy: 0.9682\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0354 - accuracy: 0.9886\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0200 - accuracy: 0.9933\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0136 - accuracy: 0.9954\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0101 - accuracy: 0.9966\n",
      "313/313 - 1s - loss: 0.0569 - accuracy: 0.9865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0569085031747818, 0.9865000247955322]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c9ce76",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1f20b4",
   "metadata": {},
   "source": [
    "## 21.6 TensorFlow2 API로 모델 작성 및 학습하기 : CIFATR-100 (1) Sequential API 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "885c8481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "857e23a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169009152/169001437 [==============================] - 3s 0us/step\n",
      "169017344/169001437 [==============================] - 3s 0us/step\n",
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6f9ed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(16, 3, activation='relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2d36d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 6s 3ms/step - loss: 3.6284 - accuracy: 0.1546\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.9350 - accuracy: 0.2785\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.6434 - accuracy: 0.3377\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.4394 - accuracy: 0.3787\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.2803 - accuracy: 0.4142\n",
      "313/313 - 1s - loss: 2.5887 - accuracy: 0.3556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5886611938476562, 0.3555999994277954]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee86173",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad62390",
   "metadata": {},
   "source": [
    "## 21.7 Tensorflow2 API로 모델 작성 및 학습하기: CIFAR-100 (2) Functional API 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a49c91ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c123e9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89985bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(32,32,3))\n",
    "\n",
    "x = keras.layers.Conv2D(16, 3, activation='relu')(inputs)\n",
    "x = keras.layers.MaxPool2D((2,2))(x)\n",
    "x = keras.layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = keras.layers.MaxPool2D((2,2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(256, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(100, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cba7aa54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 3.6378 - accuracy: 0.1531\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.9402 - accuracy: 0.2764\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.6429 - accuracy: 0.3364\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.4343 - accuracy: 0.3804\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.2858 - accuracy: 0.4096\n",
      "313/313 - 1s - loss: 2.5788 - accuracy: 0.3599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5788376331329346, 0.35989999771118164]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d790638e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da84557",
   "metadata": {},
   "source": [
    "## 21.8 Tensorflow2 API로 모델 작성 및 학습하기: CIFAR-100 (3) Subclassing 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85fbe475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a2cca58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b35494a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(16, 3, activation='relu')\n",
    "        self.maxpool1 = keras.layers.MaxPool2D((2,2))\n",
    "        self.conv2 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.maxpool2 = keras.layers.MaxPool2D((2,2))\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(256, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(100, activation='softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c26eb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 3.6076 - accuracy: 0.1551\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.9010 - accuracy: 0.2811\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.5920 - accuracy: 0.3439\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3749 - accuracy: 0.3917\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.2038 - accuracy: 0.4275\n",
      "313/313 - 1s - loss: 2.5262 - accuracy: 0.3628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.526217460632324, 0.3628000020980835]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0101966a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e852e3f8",
   "metadata": {},
   "source": [
    "## 21.9 GradientTape의 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c8bfab",
   "metadata": {},
   "source": [
    "### Automatic differentiation - GradientTape\n",
    "- tf.GradientTape는 순전파(forward pass)로 진행된 모든 연산의 중간 레이어값을 tape에 기록하고, 이를 이용해 gradient를 계산한 후 tape를 폐기하는 기능을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e386d3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 데이터 구성부분\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))\n",
    "\n",
    "# 모델 구성부분\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(16, 3, activation='relu')\n",
    "        self.maxpool1 = keras.layers.MaxPool2D((2,2))\n",
    "        self.conv2 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.maxpool2 = keras.layers.MaxPool2D((2,2))\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(256, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(100, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2c5a1e",
   "metadata": {},
   "source": [
    "- tape.gradient()를 통해 매 스텝 학습이 진행될 때마다 발생하는 그래디언트를 추출한 후 optimizer.apply_gradients()를 통해 발생한 그래디언트가 업데이트해야 할 파라미터 model.trainalbe_variables를 지정해 주는 과정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db5918cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# tf.GradientTape()를 활용한 train_step\n",
    "def train_step(features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(features)\n",
    "        loss = loss_func(labels, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7bd51de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: last batch loss = 3.2179\n",
      "Epoch 1: last batch loss = 2.7250\n",
      "Epoch 2: last batch loss = 2.5027\n",
      "Epoch 3: last batch loss = 2.2373\n",
      "Epoch 4: last batch loss = 2.0488\n",
      "It took 87.26685619354248 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def train_model(batch_size=32):\n",
    "    start = time.time()\n",
    "    for epoch in range(5):\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        for step, (x, y) in enumerate(zip(x_train, y_train)):\n",
    "            x_batch.append(x)\n",
    "            y_batch.append(y)\n",
    "            if step % batch_size == batch_size-1:\n",
    "                loss = train_step(np.array(x_batch, dtype=np.float32), np.array(y_batch, dtype=np.float32))\n",
    "                x_batch = []\n",
    "                y_batch = []\n",
    "        print('Epoch %d: last batch loss = %.4f' % (epoch, float(loss)))\n",
    "    print(\"It took {} seconds\".format(time.time() - start))\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad2dca5",
   "metadata": {},
   "source": [
    "- train_model() 메서드가 실은 우리가 그동안 사용했던 model.fit() 메서드와 기능적으로 같다는 것\n",
    "- tf.GradientTape()를 활용하면 model.compile()과 model.fit() 안에 감추어져 있던 한 스텝의 학습 단계를 끄집어내서 자유롭게 재구성할 수 있게 된다\n",
    "- 그동안 흔히 다루어 왔던 지도학습 방식과 다른 강화학습 또는 GAN(Generative Advasarial Network)의 학습을 위해서는 train_step 메서드의 재구성이 필수적이므로 tf.GradientTape()의 활용법을 꼭 숙지해두어야 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1461064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 900ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3318"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "prediction = model.predict(x_test, batch_size=x_test.shape[0], verbose=1)\n",
    "temp = sum(np.squeeze(y_test) == np.argmax(prediction, axis=1))\n",
    "temp/len(y_test)  # Accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
